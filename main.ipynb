{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Metrics used across models\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "#Dependencies used in Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "#Dependencies used in KNN\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to read our dataset. Notice that the dataset being loaded is the test.csv & train.csv and not JobApplicants.csv - the reason for that is because we have been working on different computers.\n",
    "The split dataset guarantees that the testrainsplit is consistent as it is not run on both computers.\n",
    "\n",
    "For more information on how the training set was created please visit traintestspilit.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seu Jorge</td>\n",
       "      <td>358733</td>\n",
       "      <td>False</td>\n",
       "      <td>0.641</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.401</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.423</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chyi Chin</td>\n",
       "      <td>231520</td>\n",
       "      <td>False</td>\n",
       "      <td>0.668</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.710</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.7950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babyboomboom</td>\n",
       "      <td>98386</td>\n",
       "      <td>False</td>\n",
       "      <td>0.786</td>\n",
       "      <td>9</td>\n",
       "      <td>-16.516</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sidhu Moose Wala;DIVINE</td>\n",
       "      <td>232173</td>\n",
       "      <td>False</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.817</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rumbavana</td>\n",
       "      <td>360320</td>\n",
       "      <td>False</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.742</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.696</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   artists  duration_ms  explicit  danceability  key  \\\n",
       "0                Seu Jorge       358733     False         0.641   11   \n",
       "1                Chyi Chin       231520     False         0.668    5   \n",
       "2             Babyboomboom        98386     False         0.786    9   \n",
       "3  Sidhu Moose Wala;DIVINE       232173     False         0.709    0   \n",
       "4                Rumbavana       360320     False         0.786    0   \n",
       "\n",
       "   loudness  speechiness  acousticness  instrumentalness  valence  \\\n",
       "0    -6.401       0.0604        0.1510          0.000761    0.423   \n",
       "1    -9.710       0.0353        0.7950          0.000000    0.432   \n",
       "2   -16.516       0.5730        0.6790          0.000000    0.658   \n",
       "3    -5.817       0.2450        0.0698          0.000000    0.654   \n",
       "4    -6.742       0.0456        0.5110          0.000000    0.696   \n",
       "\n",
       "   time_signature  track_genre  popularity  \n",
       "0               4            0          41  \n",
       "1               3            1          52  \n",
       "2               4            2          11  \n",
       "3               4            3          61  \n",
       "4               4            4          37  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "df_train = pd.read_csv('train_modified_no_columns.csv')\n",
    "\n",
    "# Load the test data\n",
    "df_test = pd.read_csv('test_modified_no_columns.csv')\n",
    "\n",
    "#Check headers\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113186</td>\n",
       "      <td>1</td>\n",
       "      <td>No Other Name</td>\n",
       "      <td>No Other Name</td>\n",
       "      <td>440247</td>\n",
       "      <td>False</td>\n",
       "      <td>0.369</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.984</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.00511</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42819</td>\n",
       "      <td>2</td>\n",
       "      <td>Grieving Birth</td>\n",
       "      <td>Failed Organum</td>\n",
       "      <td>93933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.171</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.586</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.00521</td>\n",
       "      <td>0.80100</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59311</td>\n",
       "      <td>3</td>\n",
       "      <td>Noise A Noise 20.4-1</td>\n",
       "      <td>Save the Trees, Pt. 1</td>\n",
       "      <td>213578</td>\n",
       "      <td>False</td>\n",
       "      <td>0.173</td>\n",
       "      <td>9</td>\n",
       "      <td>-10.071</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.61300</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90417</td>\n",
       "      <td>4</td>\n",
       "      <td>A Thousand Stars</td>\n",
       "      <td>It's Only Make Believe</td>\n",
       "      <td>146706</td>\n",
       "      <td>False</td>\n",
       "      <td>0.419</td>\n",
       "      <td>9</td>\n",
       "      <td>-13.438</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61000</td>\n",
       "      <td>5</td>\n",
       "      <td>バレッタ TypeD</td>\n",
       "      <td>月の大きさ</td>\n",
       "      <td>236293</td>\n",
       "      <td>False</td>\n",
       "      <td>0.555</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.294</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.48400</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.8130</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  artists            album_name              track_name  duration_ms  \\\n",
       "0  113186        1         No Other Name           No Other Name       440247   \n",
       "1   42819        2        Grieving Birth          Failed Organum        93933   \n",
       "2   59311        3  Noise A Noise 20.4-1   Save the Trees, Pt. 1       213578   \n",
       "3   90417        4      A Thousand Stars  It's Only Make Believe       146706   \n",
       "4   61000        5            バレッタ TypeD                   月の大きさ       236293   \n",
       "\n",
       "   explicit  danceability  key  loudness  speechiness  acousticness  \\\n",
       "0     False         0.369    7    -6.984       0.0304       0.00511   \n",
       "1     False         0.171    7    -3.586       0.1180       0.00521   \n",
       "2     False         0.173    9   -10.071       0.1440       0.61300   \n",
       "3     False         0.419    9   -13.438       0.0322       0.32000   \n",
       "4     False         0.555    9    -3.294       0.0481       0.48400   \n",
       "\n",
       "   instrumentalness  valence  time_signature  track_genre  \n",
       "0           0.00000   0.0466               4            1  \n",
       "1           0.80100   0.0294               4            2  \n",
       "2           0.00191   0.0887               3            3  \n",
       "3           0.00000   0.4620               4            4  \n",
       "4           0.00000   0.8130               4            5  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the artists column\n",
    "df_train = df_train.drop(columns = ['artists'])\n",
    "df_test = df_test.drop(columns = ['artists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'popularity_category' in the training data\n",
    "df_train['popularity_category'] = pd.qcut(df_train['popularity'], q=3, labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['explicit']\n",
    "numerical_cols = ['duration_ms', 'danceability', 'key', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'valence', 'time_signature']\n",
    "\n",
    "X_train = df_train[categorical_cols + numerical_cols]  # Input features\n",
    "y_train = df_train['popularity_category']  # Target variable\n",
    "X_test = df_test[categorical_cols + numerical_cols]\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a ColumnTransformer to transform the categorical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create a pipeline that includes the preprocessor and the Random Forest model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, max_features='sqrt', n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Train the pipeline on the training data\n",
    "pipeline.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Step 7: Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6492324561403509\n",
      "Validation F1 Score: 0.6493169396689212\n",
      "Validation Precision: 0.6507969007196577\n",
      "Validation Recall: 0.6484633078659062\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Evaluate the model\n",
    "y_pred_val = pipeline.predict(X_val)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "f1_val = f1_score(y_val, y_pred_val, average='macro')  # Adjust 'average' as appropriate for your scenario\n",
    "precision_val = precision_score(y_val, y_pred_val, average='macro')\n",
    "recall_val = recall_score(y_val, y_pred_val, average='macro')\n",
    "\n",
    "# Print the evaluation metrics for the validation set\n",
    "print(f\"Validation Accuracy: {accuracy_val}\")\n",
    "print(f\"Validation F1 Score: {f1_val}\")\n",
    "print(f\"Validation Precision: {precision_val}\")\n",
    "print(f\"Validation Recall: {recall_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GridSearchCV.__init__() got an unexpected keyword argument 'max_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__n_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m85\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m115\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m13\u001b[39m],\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__min_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m15\u001b[39m],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__min_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m8\u001b[39m]\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create a GridSearchCV object\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m \u001b[43mGridSearchCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msqrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the grid search to your data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mTypeError\u001b[0m: GridSearchCV.__init__() got an unexpected keyword argument 'max_features'"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters and their possible values\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [85, 100, 115],\n",
    "    'classifier__max_depth': [7, 10, 13],\n",
    "    'classifier__min_samples_split': [10, 12, 15],\n",
    "    'classifier__min_samples_leaf': [4, 6, 8]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1, max_features='sqrt')\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "#Print the best parameters and model\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Model: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring if min_samples_split range was set too low"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
